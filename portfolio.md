# 5년차 백엔드 개발자 포트폴리오

## 1. 소개

안녕하세요. 5년차 백엔드 개발자 [이름]입니다. 대규모 트래픽을 처리할 수 있는 확장 가능하고 안정적인 분산 시스템 설계 및 구축에 깊은 관심을 두고 있습니다. 특히 MSA(Microservice Architecture) 환경에서 비즈니스 요구사항을 기술적 해결책으로 전환하는 경험이 풍부합니다. 클린 코드와 테스트 자동화를 통해 유지보수성이 뛰어난 시스템을 만드는 것을 지향합니다.

## 2. 프로젝트: Unimal (반려동물 및 야생동물 커뮤니티 플랫폼)

### 2.1. 프로젝트 개요

**Unimal**은 사용자가 주변의 동물(반려동물, 길고양이, 야생동물 등) 사진과 정보를 위치 기반으로 공유하는 커뮤니티 서비스입니다. 실시간 알림, 동물 지도, 게시판 등 다양한 기능을 통해 사용자 간의 활발한 소통을 지원합니다.

*   **GitHub Repository:** (링크가 있다면 여기에 추가)
*   **개발 기간:** YYYY.MM ~ YYYY.MM (총 N개월)

### 2.2. 아키텍처 및 주요 기술 결정

대규모 사용자 트래픽과 서비스의 독립적인 확장을 고려하여 MSA(Microservice Architecture)를 채택했습니다. 각 서비스는 기능 단위로 명확하게 분리되어 있으며, Docker 컨테이너 환경에서 동작합니다.

![Architecture Diagram](https://user-images.githubusercontent.com/…..png)  
*(여기에 아키텍처 다이어그램 이미지를 추가하면 좋습니다.)*

#### 주요 기술 선택 이유:

*   **Kotlin & Spring Boot:** 생산성과 안정성을 모두 고려하여 선택했습니다. Kotlin의 간결한 문법과 Coroutine을 활용해 비동기 처리 성능을 높였고, Spring Boot의 강력한 생태계를 통해 개발 속도를 향상시켰습니다.
*   **gRPC (내부 통신):** 서비스 간 동기 통신에서 REST API 대비 높은 성능과 타입 안정성을 제공하는 gRPC를 채택했습니다. `proto-common` 모듈을 통해 모든 서비스의 API 계약(Contract)을 중앙에서 관리하여 통신의 일관성을 확보했습니다.
*   **Kafka (비동기 통신):** 게시물 작성 시점에 팔로워에게 실시간 알림을 보내는 등 서비스 간의 결합도를 낮추고 비동기 이벤트 처리를 위해 Kafka를 도입했습니다. 이를 통해 특정 서비스의 장애가 다른 서비스로 전파되는 것을 최소화하고 시스템 전체의 탄력성을 높였습니다.
*   **Spring Cloud Gateway:** 모든 클라이언트 요청을 처리하는 단일 진입점으로, 인증/인가, 라우팅, 로깅 등 공통 기능을 중앙에서 관리하여 각 마이크로서비스의 부담을 줄였습니다.

### 2.3. 역할 및 기여

이 프로젝트에서 백엔드 시스템의 **초기 설계부터 개발, 배포, 운영**까지 전 과정에 참여했습니다.

*   **MSA 시스템 설계 및 구축 (기여도 80%):**
    *   `User`, `Board`, `Photo`, `Notification`, `Map` 등 핵심 도메인별 마이크로서비스 구조를 설계하고 구현했습니다.
    *   `proto-common` 모듈을 설계하여 gRPC 통신 계약을 정의하고, 서비스 간 API 일관성을 유지했습니다.
*   **핵심 기능 개발:**
    *   **사용자 시스템:** JWT 기반의 인증/인가 시스템을 구축했습니다.
    *   **실시간 알림 시스템:** Kafka를 이용하여 게시물 등록, 댓글 작성 등 주요 이벤트 발생 시 관련 사용자에게 실시간 알림을 보내는 기능을 개발했습니다. Producer와 Consumer 로직을 안정적으로 구현하여 대량의 메시지도 지연 없이 처리하도록 했습니다.
    *   **이미지 처리 파이프라인:** AWS S3를 활용하여 이미지 업로드 및 CDN 연동을 구현했습니다.
*   **인프라 구축 및 DevOps:**
    *   `Docker`와 `docker-compose`를 사용하여 로컬 및 테스트 환경을 구축하고, 애플리케이션의 배포를 자동화했습니다.
    *   PostgreSQL 스키마를 설계하고, Spring Data JPA를 사용하여 데이터 접근 로직을 구현했습니다. 인덱스 최적화를 통해 주요 API의 응답 속도를 개선했습니다.
    *   Redis를 도입하여 자주 조회되는 데이터를 캐싱함으로써 DB 부하를 줄이고 성능을 향상시켰습니다.

### 2.4. 기술적 도전 및 해결 사례

#### 1. 대규모 실시간 알림 처리 시 성능 저하 문제

**문제:** 인기 있는 사용자가 게시물을 올리면 수만 명의 팔로워에게 동시에 알림을 보내야 했습니다. 초기 구현은 동기 방식으로 처리되어 알림 발송이 완료될 때까지 API 응답이 지연되는 심각한 문제가 있었습니다.

**해결:**
1.  **Kafka 도입:** 게시물 생성 이벤트를 Kafka 토픽에 발행(Produce)하는 방식으로 변경하여 API 응답과 알림 발송 로직을 완전히 분리했습니다.
2.  **Notification 서비스 구현:** 해당 토픽을 구독(Consume)하는 별도의 `Notification` 서비스를 구현하여 알림 발송을 비동기적으로 처리했습니다.
3.  **결과:** API 응답 시간을 10ms 이내로 단축했으며, Kafka 클러스터 확장을 통해 수십만 건의 알림도 안정적으로 처리할 수 있는 확장성을 확보했습니다.

#### 2. 서비스 간 데이터 의존성 및 일관성 문제

**문제:** MSA 환경에서 각 서비스가 자체 데이터베이스를 가지면서 서비스 간 데이터 정합성을 맞추기 어려웠습니다. 예를 들어, 사용자가 탈퇴했을 때 해당 사용자가 작성한 게시물이나 댓글을 처리하는 로직이 복잡했습니다.

**해결:**
1.  **Eventual Consistency 적용:** Kafka를 이용한 이벤트 기반 아키텍처를 확장하여 '사용자 탈퇴' 이벤트를 발행했습니다.
2.  **관련 서비스의 이벤트 구독:** `Board`, `Photo` 등 관련 서비스들이 해당 이벤트를 구독하여 각 서비스의 정책에 맞게 데이터를 처리하도록 구현했습니다. (예: `Board` 서비스는 사용자 정보를 '알 수 없는 사용자'로 변경)
3.  **결과:** 서비스 간의 강한 결합을 제거하고, 각 서비스가 독립적으로 데이터를 처리할 수 있는 유연한 구조를 만들었습니다. 이를 통해 시스템 전체의 복잡도를 낮추고 유지보수성을 크게 향상시켰습니다.

### 2.5. 사용 기술

*   **Language:** Kotlin, Java
*   **Framework:** Spring Boot, Spring Cloud Gateway, Spring Data JPA
*   **Database:** PostgreSQL, Redis
*   **Messaging/Event Stream:** Apache Kafka, gRPC
*   **DevOps & Infra:** Docker, docker-compose, AWS S3, Git
*   **Testing:** JUnit5, MockK

## 3. 연락처

*   **Email:** your.email@example.com
*   **GitHub:** https://github.com/your-github
*   **LinkedIn:** https://www.linkedin.com/in/your-profile/
